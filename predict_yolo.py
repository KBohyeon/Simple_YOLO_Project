# predict_yolo.py - YOLO ì˜ˆì¸¡ ë° í…ŒìŠ¤íŠ¸

import torch
import torchvision.transforms as transforms
from PIL import Image
import matplotlib.pyplot as plt
import argparse
import time
import json
from pathlib import Path
import numpy as np

from yolo_model import SimpleYOLO, decode_predictions, non_max_suppression, visualize_predictions, load_model
from config import *

class YOLOPredictor:
    """YOLO ì˜ˆì¸¡ í´ë˜ìŠ¤"""
    
    def __init__(self, model_path, confidence_threshold=0.3, nms_threshold=0.5):
        self.model_path = Path(model_path)
        self.confidence_threshold = confidence_threshold
        self.nms_threshold = nms_threshold
        self.device = DEVICE
        
        # ëª¨ë¸ ë¡œë“œ
        self.load_model()
        
        # ì „ì²˜ë¦¬ ë³€í™˜
        self.transform = transforms.Compose([
            transforms.Resize((MODEL_CONFIG['img_size'], MODEL_CONFIG['img_size'])),
            transforms.ToTensor(),
            transforms.Normalize(mean=NORMALIZE_MEAN, std=NORMALIZE_STD)
        ])
        
    def load_model(self):
        """í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ"""
        if not self.model_path.exists():
            raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {self.model_path}")
        
        print(f"ğŸ”„ ëª¨ë¸ ë¡œë”© ì¤‘: {self.model_path}")
        
        self.model = load_model(self.model_path, self.device)
        
        print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
        
    def predict_image(self, image_path, save_result=True, show_result=True):
        """ë‹¨ì¼ ì´ë¯¸ì§€ ì˜ˆì¸¡"""
        print(f"\nğŸ” ì´ë¯¸ì§€ ì˜ˆì¸¡: {image_path}")
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        image = Image.open(image_path).convert('RGB')
        orig_width, orig_height = image.size
        
        print(f"   - ì›ë³¸ í¬ê¸°: {orig_width}Ã—{orig_height}")
        
        # ì „ì²˜ë¦¬
        start_time = time.time()
        input_tensor = self.transform(image).unsqueeze(0).to(self.device)
        
        # ì˜ˆì¸¡
        with torch.no_grad():
            output = self.model(input_tensor)
        
        # í›„ì²˜ë¦¬
        detections = decode_predictions(output[0], self.confidence_threshold)
        
        # NMS ì ìš©
        if detections:
            boxes = torch.tensor([[d[0], d[1], d[2], d[3]] for d in detections])
            scores = torch.tensor([d[4] for d in detections])
            
            if len(boxes) > 1:
                final_boxes, final_scores = non_max_suppression(
                    boxes, scores, self.nms_threshold
                )
                
                # ìµœì¢… ê²€ì¶œ ê²°ê³¼ ìƒì„±
                final_detections = []
                for i in range(len(final_boxes)):
                    x, y, w, h = final_boxes[i].tolist()
                    conf = final_scores[i].item()
                    class_id = detections[i][5]  # ì›ë˜ í´ë˜ìŠ¤ ID ìœ ì§€
                    
                    # ì›ë³¸ í¬ê¸°ë¡œ ìŠ¤ì¼€ì¼ë§
                    x_pixel = x * orig_width
                    y_pixel = y * orig_height
                    w_pixel = w * orig_width
                    h_pixel = h * orig_height
                    
                    final_detections.append({
                        'class': CLASSES[class_id],
                        'confidence': conf,
                        'bbox': [x_pixel, y_pixel, w_pixel, h_pixel],
                        'class_id': class_id
                    })
            else:
                # ë‹¨ì¼ ê²€ì¶œ
                if detections:
                    d = detections[0]
                    x, y, w, h, conf, class_id = d
                    
                    x_pixel = x * orig_width
                    y_pixel = y * orig_height
                    w_pixel = w * orig_width
                    h_pixel = h * orig_height
                    
                    final_detections = [{
                        'class': CLASSES[class_id],
                        'confidence': conf,
                        'bbox': [x_pixel, y_pixel, w_pixel, h_pixel],
                        'class_id': class_id
                    }]
                else:
                    final_detections = []
        else:
            final_detections = []
        
        inference_time = time.time() - start_time
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"   - ì¶”ë¡  ì‹œê°„: {inference_time*1000:.1f}ms")
        print(f"   - ê²€ì¶œëœ ê°ì²´: {len(final_detections)}ê°œ")
        
        for i, det in enumerate(final_detections):
            x, y, w, h = det['bbox']
            print(f"     {i+1}. {det['class']}: {det['confidence']:.3f} "
                  f"({int(x)}, {int(y)}, {int(w)}, {int(h)})")
        
        # ê²°ê³¼ ì‹œê°í™” ë° ì €ì¥
        if save_result or show_result:
            result_path = None
            if save_result:
                PATHS['results_dir'].mkdir(parents=True, exist_ok=True)
                result_filename = f"result_{Path(image_path).stem}.png"
                result_path = PATHS['results_dir'] / result_filename
            
            visualize_predictions(
                image, final_detections, 
                save_path=result_path, 
                show_plot=show_result
            )
        
        return final_detections, inference_time
    
    def predict_batch(self, image_folder, output_file=None):
        """í´ë” ë‚´ ëª¨ë“  ì´ë¯¸ì§€ ì˜ˆì¸¡"""
        image_folder = Path(image_folder)
        
        if not image_folder.exists():
            raise FileNotFoundError(f"í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {image_folder}")
        
        # ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°
        image_files = []
        for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:
            image_files.extend(image_folder.glob(ext))
            image_files.extend(image_folder.glob(ext.upper()))
        
        if not image_files:
            print(f"âŒ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_folder}")
            return
        
        print(f"\nğŸ“ ë°°ì¹˜ ì˜ˆì¸¡: {len(image_files)}ê°œ ì´ë¯¸ì§€")
        print("=" * 50)
        
        all_results = []
        total_time = 0
        total_objects = 0
        
        for i, image_path in enumerate(image_files, 1):
            print(f"\n[{i}/{len(image_files)}] {image_path.name}")
            
            try:
                detections, inference_time = self.predict_image(
                    image_path, save_result=True, show_result=False
                )
                
                total_time += inference_time
                total_objects += len(detections)
                
                # ê²°ê³¼ ê¸°ë¡
                result = {
                    'image_path': str(image_path),
                    'detections': detections,
                    'inference_time': inference_time,
                    'num_objects': len(detections)
                }
                all_results.append(result)
                
            except Exception as e:
                print(f"   âŒ ì˜ˆì¸¡ ì‹¤íŒ¨: {str(e)}")
                continue
        
        # ì „ì²´ í†µê³„
        avg_time = total_time / len(all_results) if all_results else 0
        avg_objects = total_objects / len(all_results) if all_results else 0
        
        print("\n" + "=" * 50)
        print("ğŸ“Š ë°°ì¹˜ ì˜ˆì¸¡ ì™„ë£Œ!")
        print(f"   - ì²˜ë¦¬ëœ ì´ë¯¸ì§€: {len(all_results)}ê°œ")
        print(f"   - ì´ ê²€ì¶œ ê°ì²´: {total_objects}ê°œ")
        print(f"   - í‰ê·  ì¶”ë¡  ì‹œê°„: {avg_time*1000:.1f}ms")
        print(f"   - ì´ë¯¸ì§€ë‹¹ í‰ê·  ê°ì²´: {avg_objects:.1f}ê°œ")
        print(f"   - ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {PATHS['results_dir']}")
        
        # ê²°ê³¼ íŒŒì¼ ì €ì¥
        if output_file:
            output_path = Path(output_file)
        else:
            output_path = PATHS['results_dir'] / 'batch_results.json'
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump({
                'config': {
                    'model_path': str(self.model_path),
                    'confidence_threshold': self.confidence_threshold,
                    'nms_threshold': self.nms_threshold,
                    'classes': CLASSES
                },
                'statistics': {
                    'total_images': len(all_results),
                    'total_objects': total_objects,
                    'avg_inference_time': avg_time,
                    'avg_objects_per_image': avg_objects
                },
                'results': all_results
            }, f, indent=2, ensure_ascii=False)
        
        print(f"   - ê²°ê³¼ JSON: {output_path}")
        
        return all_results
    
    def evaluate_performance(self, test_folder=None):
        """ì„±ëŠ¥ í‰ê°€ (ê°„ë‹¨í•œ í†µê³„)"""
        if test_folder:
            results = self.predict_batch(test_folder, show_result=False)
        else:
            print("í…ŒìŠ¤íŠ¸ í´ë”ê°€ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        if not results:
            return
        
        # í´ë˜ìŠ¤ë³„ í†µê³„
        class_counts = {cls: 0 for cls in CLASSES}
        confidence_scores = {cls: [] for cls in CLASSES}
        
        for result in results:
            for det in result['detections']:
                class_name = det['class']
                confidence = det['confidence']
                
                class_counts[class_name] += 1
                confidence_scores[class_name].append(confidence)
        
        # í†µê³„ ì¶œë ¥
        print("\nğŸ“Š ì„±ëŠ¥ í†µê³„:")
        print("=" * 40)
        
        for class_name in CLASSES:
            count = class_counts[class_name]
            if count > 0:
                avg_conf = np.mean(confidence_scores[class_name])
                min_conf = np.min(confidence_scores[class_name])
                max_conf = np.max(confidence_scores[class_name])
                
                print(f"{class_name}:")
                print(f"   - ê²€ì¶œ ìˆ˜: {count}")
                print(f"   - í‰ê·  ì‹ ë¢°ë„: {avg_conf:.3f}")
                print(f"   - ì‹ ë¢°ë„ ë²”ìœ„: {min_conf:.3f} ~ {max_conf:.3f}")
            else:
                print(f"{class_name}: ê²€ì¶œë˜ì§€ ì•ŠìŒ")
        
        # ì‹ ë¢°ë„ ë¶„í¬ ì‹œê°í™”
        self.plot_confidence_distribution(confidence_scores)
    
    def plot_confidence_distribution(self, confidence_scores):
        """ì‹ ë¢°ë„ ë¶„í¬ ì‹œê°í™”"""
        plt.figure(figsize=(12, 6))
        
        # í´ë˜ìŠ¤ë³„ ì‹ ë¢°ë„ ë¶„í¬
        plt.subplot(1, 2, 1)
        for i, (class_name, scores) in enumerate(confidence_scores.items()):
            if scores:
                plt.hist(scores, bins=20, alpha=0.7, label=class_name, color=COLORS[i])
        
        plt.xlabel('ì‹ ë¢°ë„')
        plt.ylabel('ë¹ˆë„')
        plt.title('í´ë˜ìŠ¤ë³„ ì‹ ë¢°ë„ ë¶„í¬')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # ì „ì²´ ì‹ ë¢°ë„ ë¶„í¬
        plt.subplot(1, 2, 2)
        all_scores = []
        for scores in confidence_scores.values():
            all_scores.extend(scores)
        
        if all_scores:
            plt.hist(all_scores, bins=30, alpha=0.7, color='skyblue', edgecolor='black')
            plt.axvline(np.mean(all_scores), color='red', linestyle='--', 
                       label=f'í‰ê· : {np.mean(all_scores):.3f}')
            plt.axvline(self.confidence_threshold, color='green', linestyle='--',
                       label=f'ì„ê³„ê°’: {self.confidence_threshold}')
        
        plt.xlabel('ì‹ ë¢°ë„')
        plt.ylabel('ë¹ˆë„')
        plt.title('ì „ì²´ ì‹ ë¢°ë„ ë¶„í¬')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # ì €ì¥
        plot_path = PATHS['results_dir'] / 'confidence_distribution.png'
        plt.savefig(plot_path, dpi=150, bbox_inches='tight')
        plt.show()
        
        print(f"ğŸ“Š ì‹ ë¢°ë„ ë¶„í¬ ê·¸ë˜í”„: {plot_path}")

def check_model_file(model_path):
    """ëª¨ë¸ íŒŒì¼ í™•ì¸"""
    model_path = Path(model_path)
    
    if not model_path.exists():
        print(f"âŒ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        
        # ëŒ€ì•ˆ ëª¨ë¸ ì°¾ê¸°
        models_dir = PATHS['models_dir']
        if models_dir.exists():
            model_files = list(models_dir.glob('*.pth'))
            if model_files:
                print(f"\nğŸ“ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ë“¤:")
                for i, model_file in enumerate(model_files, 1):
                    print(f"   {i}. {model_file.name}")
                return None
        
        print("\nğŸ’¡ ë¨¼ì € train_yolo.pyë¥¼ ì‹¤í–‰í•´ì„œ ëª¨ë¸ì„ í›ˆë ¨í•˜ì„¸ìš”.")
        return None
    
    return model_path

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='YOLO ëª¨ë¸ ì˜ˆì¸¡')
    parser.add_argument('--model', type=str, 
                       default='yolo_dataset/models/best_yolo_model.pth',
                       help='ëª¨ë¸ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--image', type=str,
                       help='ì˜ˆì¸¡í•  ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--folder', type=str,
                       help='ì˜ˆì¸¡í•  ì´ë¯¸ì§€ í´ë” ê²½ë¡œ')
    parser.add_argument('--confidence', type=float, default=0.3,
                       help='ì‹ ë¢°ë„ ì„ê³„ê°’')
    parser.add_argument('--nms', type=float, default=0.5,
                       help='NMS IoU ì„ê³„ê°’')
    parser.add_argument('--no-show', action='store_true',
                       help='ê²°ê³¼ ì´ë¯¸ì§€ í‘œì‹œ ì•ˆí•¨')
    parser.add_argument('--no-save', action='store_true',
                       help='ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥ ì•ˆí•¨')
    parser.add_argument('--eval', action='store_true',
                       help='ì„±ëŠ¥ í‰ê°€ ìˆ˜í–‰')
    
    args = parser.parse_args()
    
    print("=" * 60)
    print("ğŸ” YOLO ê°ì²´ ê²€ì¶œ ì˜ˆì¸¡ ì‹œìŠ¤í…œ")
    print("=" * 60)
    print(f"í´ë˜ìŠ¤: {', '.join(CLASSES)}")
    
    # ë””ë ‰í† ë¦¬ ì„¤ì •
    setup_directories()
    
    # ëª¨ë¸ íŒŒì¼ í™•ì¸
    model_path = check_model_file(args.model)
    if not model_path:
        return
    
    try:
        # ì˜ˆì¸¡ê¸° ì´ˆê¸°í™”
        predictor = YOLOPredictor(
            model_path=model_path,
            confidence_threshold=args.confidence,
            nms_threshold=args.nms
        )
        
        print(f"\nğŸ› ï¸ ì˜ˆì¸¡ ì„¤ì •:")
        print(f"   - ì‹ ë¢°ë„ ì„ê³„ê°’: {args.confidence}")
        print(f"   - NMS ì„ê³„ê°’: {args.nms}")
        
        # ì˜ˆì¸¡ ì‹¤í–‰
        if args.image:
            # ë‹¨ì¼ ì´ë¯¸ì§€ ì˜ˆì¸¡
            if not Path(args.image).exists():
                print(f"âŒ ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {args.image}")
                return
            
            predictor.predict_image(
                args.image,
                save_result=not args.no_save,
                show_result=not args.no_show
            )
            
        elif args.folder:
            # í´ë” ë°°ì¹˜ ì˜ˆì¸¡
            if not Path(args.folder).exists():
                print(f"âŒ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {args.folder}")
                return
            
            predictor.predict_batch(args.folder)
            
            # ì„±ëŠ¥ í‰ê°€
            if args.eval:
                predictor.evaluate_performance(args.folder)
                
        else:
            # ëŒ€í™”í˜• ëª¨ë“œ
            print("\nğŸ® ëŒ€í™”í˜• ëª¨ë“œ")
            print("ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ê±°ë‚˜ 'quit'ë¡œ ì¢…ë£Œí•˜ì„¸ìš”.")
            
            while True:
                image_path = input("\nì´ë¯¸ì§€ ê²½ë¡œ: ").strip()
                
                if image_path.lower() in ['quit', 'q', 'exit']:
                    break
                
                if not image_path:
                    continue
                
                if not Path(image_path).exists():
                    print(f"âŒ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {image_path}")
                    continue
                
                try:
                    predictor.predict_image(
                        image_path,
                        save_result=not args.no_save,
                        show_result=not args.no_show
                    )
                except Exception as e:
                    print(f"âŒ ì˜ˆì¸¡ ì‹¤íŒ¨: {str(e)}")
    
    except Exception as e:
        print(f"\nâŒ ì˜ˆì¸¡ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()